{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgaqxrCBIHWO"
      },
      "source": [
        "# Transfer learning - Cats vs. Dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmnWkSRslRb"
      },
      "source": [
        "Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aizfyvfms_nt"
      },
      "outputs": [],
      "source": [
        "# !unzip train.zip -d train/\n",
        "# !unzip test.zip -d test/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPKXzBdsSai"
      },
      "source": [
        "Code to initiliaze Tensorflow 2.0 in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RHeyqF6rev2"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "%load_ext tensorboard\n",
        "import datetime\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9TtiitutEm8"
      },
      "source": [
        "**[TODO] Create a data loader function that returns a tuple with a tf.float32 tensor for the image and a label. Images must be resized to 128x128.**\n",
        "**N.B.: filenames are formatted as class.number.jpg**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlFW9kPUtpys"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(filename):  # load images\n",
        "    image = tf.io.read_file(filename)   # read the raw data from the file as a string\n",
        "    image = tf.image.decode_jpeg(image, channels=3) # decode the jpeg image to a tensor\n",
        "\n",
        "    image = tf.image.resize(image, [128, 128])  # resize the image to 128x128\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # transform the image to a tf.float32 type and normalize it to [0, 1]\n",
        "    return image\n",
        "\n",
        "def parse_filename(filename): # load labels\n",
        "    label = tf.strings.split(filename, sep='/') # split the filename by '/' (label[0]: 'train', label[1]: 'class.number.jpg')\n",
        "    label = tf.strings.split(label[-1], sep='.')    # split the last element of the filename by '.' (label[0]: 'class', label[1]: 'number', label[2]: 'jpg')\n",
        "    label = tf.strings.to_number(label[0], out_type=tf.int32)   # convert the label[0] to a tf.int32 type\n",
        "    return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYbzGd5rcyeN"
      },
      "source": [
        "**[TODO] Create a tf.Dataset, map the loader function and prepare a batch object for training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvP9ga5RcyB-"
      },
      "outputs": [],
      "source": [
        "trainDataSet = tf.data.Dataset.list_files('train/*')    # create a dataset from the filenames (filename: train/class.number.jpg)\n",
        "testDataSet = tf.data.Dataset.list_files('test/*')  # create a dataset from the filenames (filename: test/class.number.jpg)\n",
        "trainDataSet = trainDataSet.map(lambda x: (load_and_preprocess_image(x), parse_filename(x)))    # for each filename, load the image and the label\n",
        "testDataSet = testDataSet.map(lambda x: (load_and_preprocess_image(x), parse_filename(x)))  # for each filename, load the image and the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riIKsGjMK2KT"
      },
      "source": [
        "**Prepare Keras callback for Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grf-GiJFK-sS"
      },
      "outputs": [],
      "source": [
        "# logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# %tensorboard --logdir logs\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, update_freq='batch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVlXyF_8xGsW"
      },
      "source": [
        "**[TODO] Import the MobileNetV2 model trained on ImageNet without the final layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C6JfgQNxf9P"
      },
      "outputs": [],
      "source": [
        "# because build a deep learning model can be too complex, we can consider to use a pre-trained model for performing feature extraction, and then add the final layer to perform the\n",
        "# classification as we want\n",
        "\n",
        "# import the MobileNetV2 model, input_shape is the shape of the images. They have 3 channels cause they are RGB images\n",
        "# include_top=False means that we exclude the last fully connected layer of the model\n",
        "# weights='imagenet' means that we initialize the model with pre-trained weights on ImageNet\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')    # load the MobileNetV2 model7\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R4fFS0HcX-t"
      },
      "source": [
        "**[TODO] Add a final classification layer for 2 classes and create the final Keras model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDvBDCVFcXmo"
      },
      "outputs": [],
      "source": [
        "# We know that the final layer, the one that performs the classification through the softmax function, need that the input is a vector. This is why, as seen in the previous laboratory, we\n",
        "# have performed a flattening operation on the input. The problem of flattening is that than the classification layer depends on the size of the input (HxW), so if the model receive an image\n",
        "# with different shapes then the classification will not work. This is why in this case we use the GlobalAveragePooling2D layer, cause we want that our model could work with images of\n",
        "# different shapes. What GlobalAvaragePooling2D does is to evaluate the mean value of each image feature map and build a F dimensional vector where each value rappresent the mean value of\n",
        "# the image on that channel.\n",
        "x = base_model.output   # get the output of the model, on it we will add the final layers\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) # evaluate the mean value of each image feature map. So we receive an input of shape (HxWxF) and we return an output of shape (F)\n",
        "y = tf.keras.layers.Dense(2, activation='softmax')(x)  # build a pdf with the two possible classes, dog and cat\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=y)    # create the final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Arv2jyxgSz"
      },
      "source": [
        "**[TODO] Compile the Keras model: specify the optimization algorithm, the loss function and the test metric**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM9_th7SxlmM"
      },
      "outputs": [],
      "source": [
        "lr = 0.01   # learning rate\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgY8SK7MxmBE"
      },
      "source": [
        "**[TODO] Train the Keras model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8-x6iwSxqqM"
      },
      "outputs": [],
      "source": [
        "model.fit(trainDataSet.batch(32), epochs=5)    # train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QhCHMnVFWv3"
      },
      "source": [
        "**[TODO] Print model summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqTgD3xRFaJN"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uva5AeZrxrf0"
      },
      "source": [
        "**[TODO] Test the Keras model by computing the accuracy the whole test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5536AAv7x1Al"
      },
      "outputs": [],
      "source": [
        "model.evaluate(trainDataSet.batch(32))    # evaluate the model on the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWMWEosqqX1b"
      },
      "source": [
        "**[TODO] Load Test image 'test/0.1047.jpg', visualize it and check the network prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMVCrCxsqkh_"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(x_test[47].reshape(28, 28), cmap='gray')\n",
        "# plt.title(f'Label: {y_test[47]}')\n",
        "# plt.show()\n",
        "\n",
        "# y_pred = model.predict(x_test[47][np.newaxis, :, :, :])\n",
        "# print(f'Predicted label: {np.argmax(y_pred)}')\n",
        "\n",
        "showImage = tf.io.read_file('test/0.1047.jpg')   # read the raw data from the file as a string\n",
        "showImage = tf.image.decode_jpeg(showImage)  # decode the jpeg image to a tensor\n",
        "plt.imshow(showImage)   # show the image\n",
        "plt.show()\n",
        "\n",
        "# prepare the image for the model\n",
        "showImage = tf.image.resize(showImage, [128, 128])  # resize the image to 128x128\n",
        "showImage = tf.cast(showImage, tf.float32) / 255.0  # transform the image to a tf.float32 type and normalize it to [0, 1]\n",
        "showImage = showImage[tf.newaxis, :, :, :]  # add a batch dimension\n",
        "predict = model.predict(showImage)  # predict the label of the image\n",
        "print(f'Predicted label: {np.argmax(predict)}')    # print the predicted label"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}