{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zi0BryVXuc9L"
   },
   "source": [
    "# Image segmentation and neural network quantization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "goOT4IQJvHpj"
   },
   "source": [
    "Here are all the import statements needed for all the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6042,
     "status": "ok",
     "timestamp": 1658839820739,
     "user": {
      "displayName": "Diego Valsesia",
      "userId": "06947720101571863244"
     },
     "user_tz": -120
    },
    "id": "VPgzPXzLtrwO"
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ! pip install tensorflow_model_optimization\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfmot\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/__init__.py:86\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# To ensure users only access the expected public API, the API structure is\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# created in the `api` directory. Import all api modules.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Import API modules for Tensorflow Model Optimization.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Module containing code for clustering.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/keras/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_scope\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_weights\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strip_clustering\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_wrapper\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clusterable_layer\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_registry\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_ops\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m     25\u001b[0m k \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mbackend\n\u001b[1;32m     26\u001b[0m CentroidInitialization \u001b[38;5;241m=\u001b[39m cluster_config\u001b[38;5;241m.\u001b[39mCentroidInitialization\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:41\u001b[0m\n\u001b[1;32m     37\u001b[0m     keras_internal \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m keras_internal\n\u001b[0;32m---> 41\u001b[0m keras \u001b[38;5;241m=\u001b[39m \u001b[43m_get_keras_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massign\u001b[39m(ref, value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massign\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:33\u001b[0m, in \u001b[0;36m_get_keras_instance\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_USE_LEGACY_KERAS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Use Keras 2.\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m version_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_fn \u001b[38;5;129;01mand\u001b[39;00m version_fn()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras_internal\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,unused-import\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    205\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.legacy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m   ):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not available with Keras 3.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    205\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.legacy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m   ):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not available with Keras 3.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 210 (1457 times), LazyLoader._load at line 52 (1457 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\u001b[38;5;241m.\u001b[39mstartswith(\n\u001b[1;32m    205\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.legacy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m   ):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not available with Keras 3.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/Dev/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "# %load_ext tensorboard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ! pip install tensorflow_model_optimization\n",
    "# import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hyGOZSRzbjlK"
   },
   "source": [
    "Loading the Sentinel 2 dataset. Images and labels are padded to be 128x128 in size and normalized by their maximum value. 40 images are used for the train partition (X_train, Y_train) and 10 for testing (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2491,
     "status": "ok",
     "timestamp": 1658840039263,
     "user": {
      "displayName": "Diego Valsesia",
      "userId": "06947720101571863244"
     },
     "user_tz": -120
    },
    "id": "exwEclbKbwHZ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loaded = np.load('sentinel2.npz')\n",
    "X = loaded['X'].astype(np.float32)  # images dataset\n",
    "Y = loaded['Y'].astype(np.float32)  # class dataset associated to each pixel (1 means coltivated land, 0 otherwise)\n",
    "X = np.pad(X, ((0,0),(3,3),(3,3),(0,0)))\n",
    "Y = np.pad(Y, ((0,0),(3,3),(3,3),(0,0)))\n",
    "X_train = X[:40]/np.max(X[:40]) # divedes datasets into training and testing\n",
    "X_test = X[40:]/np.max(X[:40])\n",
    "Y_train = Y[:40]\n",
    "Y_test = Y[40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoIe_RR6bweD"
   },
   "source": [
    "**[TODO]** Implement the U-net neural network for segmentation as drawn in the lab document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1658840628957,
     "user": {
      "displayName": "Diego Valsesia",
      "userId": "06947720101571863244"
     },
     "user_tz": -120
    },
    "id": "jEI_50VVhFk_"
   },
   "outputs": [],
   "source": [
    "# The structure of the U-net NN follows the one that we have seen in the lecture. In the lecture we have seen the Res-Net NN that introduces skip connections between layers.\n",
    "# This structure is useful cause the NN can better understand the relations between inputs and outputs, and it can perform channel attention or spatial attention.\n",
    "# Channel attention consists in weighting the feature map with a coefficent evaluated on the input of the layer.\n",
    "# Spatial attention is very similar and consists in weighting the pixels shared on the features of the image.\n",
    "# When we introduce skip connection we need to concatenate two output togheter on the features space, for doing so we must consider that they should have the same shape HxW.\n",
    "# In this NN we see also how encoding and decoding works. Encoding is used to perform features extraction through convolutional layers that reduce the size of the image but increase the number\n",
    "# of feature maps. In this case for reducing the size of the image we are changing the strides. Strides means the jump that the kernel does on the image during the convolution, and use this \n",
    "# value equals to 2 means that we are halving the size of the input image.\n",
    "# Decondig is used to recontruct the image from the features extracted through the encoding. The deconding operation is used also for images segmentation. \n",
    "# In this case the deconding operation recontruct the image through concatenation with some encoding outputs for adding new features and so more details and then it uses UpSampling2D\n",
    "# for increasing the size of the image. This is done by adding zeros around the image and then interpolate them with the other pixels. \n",
    "\n",
    "def unet(input_shape):\n",
    "  # first layer\n",
    "  inputs = tf.keras.Input(shape=input_shape)\n",
    "  x = tf.keras.layers.Conv2D(64, 3, strides=1, activation='relu', padding='same')(inputs) # more we go deeper on the levels and more we increase the number of feature maps extracted, because we want to extract more complex features\n",
    "  x = tf.keras.layers.BatchNormalization()(x) # batch normalization performs a standardization of the input of the layer by using statistics evaluated on a batch. This is useful to avoid the vanishing and expoding gradient problem\n",
    "  x = tf.keras.layers.ReLU()(x) # non linear activation function, important cause a linear activation function would make the NN a linear model and so we would lost the advantages of having deep layers\n",
    "  # the output of this layer is H x W x 64\n",
    "  # second layer - concatenated to the first\n",
    "  x = tf.keras.layers.Conv2D(64, 3, strides=1, activation='relu', padding='same')(x)\n",
    "  x = tf.keras.layers.BatchNormalization()(x)\n",
    "  x = tf.keras.layers.ReLU()(x)\n",
    "  # the output of this layer is H x W x 64\n",
    "  # third layer\n",
    "  x1 = tf.keras.layers.Conv2D(128, 3, strides=2, activation='relu', padding='same')(x)  # strides = 2 means that the kernel of the convolution will jump 2 pixels at a time on the image, so the result of the convolution will be halved\n",
    "  x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "  x1 = tf.keras.layers.ReLU()(x1)\n",
    "  # the output of this layer is H/2 x W/2 x 128\n",
    "  # fourth layer\n",
    "  x2 = tf.keras.layers.Conv2D(256, 3, strides=2, activation='relu', padding='same')(x1)\n",
    "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "  x2 = tf.keras.layers.ReLU()(x2)\n",
    "  # the output of this layer is H/4 x W/4 x 256\n",
    "  # fifth layer - concatenated to the fourth\n",
    "  x2 = tf.keras.layers.Conv2D(256, 3, strides=1, activation='relu', padding='same')(x2)\n",
    "  x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "  x2 = tf.keras.layers.ReLU()(x2)\n",
    "  x2 = tf.keras.layers.UpSampling2D(size=(2,2))(x2) # upsample the image by doubling both the dimensions\n",
    "  x2 = tf.keras.layers.concatenate([x2, x1])  # concatenate the output of the layer with the output of the third layer by the features space, they should have the same image size\n",
    "  # the output of this layer is H/2 x W/2 x 256+128\n",
    "  # sixth layer\n",
    "  x3 = tf.keras.layers.Conv2D(128, 3, strides=1, activation='relu', padding='same')(x2)\n",
    "  x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "  x3 = tf.keras.layers.ReLU()(x3)\n",
    "  x3 = tf.keras.layers.UpSampling2D(size=(2,2))(x3)\n",
    "  x3 = tf.keras.layers.concatenate([x3, x]) # concatenate the output of the layer with the output of the first-second layer by the features space, they should have the same image size\n",
    "  # the output of this layer is H x W x 128+64\n",
    "  # seventh layer\n",
    "  x4 = tf.keras.layers.Conv2D(64, 3, strides=1, activation='relu', padding='same')(x3)\n",
    "  x4 = tf.keras.layers.BatchNormalization()(x4)\n",
    "  x4 = tf.keras.layers.ReLU()(x4)\n",
    "  # the output of this layer is H x W x 64\n",
    "\n",
    "  # note that the last layer is not a Dense layer that performs the classification. This because we are performing image segmentation and not image classification, so the results of the NN is an image and not a class.\n",
    "  outputs = tf.keras.layers.Conv2D(2, 1, activation='softmax')(x4)  # softmax will create a pdf between the two possible classes, dog or cat\n",
    "  #outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(x4) # sigmoid maps the input value in a probability between 0 and 1, it doesn't build a pdf. It return the class with the highest probability\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "  return model\n",
    "\n",
    "Unet_model = unet((256,256,12)) # the input shape is 256x256x12\n",
    "Unet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg-zKuEspL7X"
   },
   "source": [
    "**[TODO]** Compile and train the model (might take some time...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300739,
     "status": "ok",
     "timestamp": 1658840933260,
     "user": {
      "displayName": "Diego Valsesia",
      "userId": "06947720101571863244"
     },
     "user_tz": -120
    },
    "id": "-voOsHhj9yz1",
    "outputId": "51c6c4b7-bf81-4c37-a334-7744873f7959"
   },
   "outputs": [],
   "source": [
    "Unet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "Unet_model.fit(X_train, Y_train, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OauN6dCVqTXV"
   },
   "source": [
    "**[TODO]** Test the model on the test set and measure the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1658840956409,
     "user": {
      "displayName": "Diego Valsesia",
      "userId": "06947720101571863244"
     },
     "user_tz": -120
    },
    "id": "0pQt0Z9bI9FA"
   },
   "outputs": [],
   "source": [
    "Unet_model.evaluate(X_test, Y_test)\n",
    "\n",
    "image = Y_test[-1]\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('Ground trouth image')\n",
    "plt.show()\n",
    "\n",
    "predict_im = Unet_model.predict(X_test[-1].reshape(1,256,256,12))\n",
    "predict_im = np.squeeze(predict_im)\n",
    "predict_im = np.argmax(predict_im, axis=-1)\n",
    "plt.imshow(predict_im, 'gray')\n",
    "plt.title('Predicted image')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO]** Convert model to TFLite with 8-bit weight quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our model we have many parameters and each is saved as float32. This cost to use a lot of memory space, so we want to reduce the dimension of these parameters. For doing so we can \n",
    "# perform quantization, so we can quantize each float parameter to an int parameter that can be rappresented with only 8 bits. \n",
    "# PTQ (Post Training Quantization) quantize each parameter on an already trained neural network. This type of quantization is the faster and the easiest to implement, but it can reduce the\n",
    "# accuracy of the model, cause the quantization is chaning the optimal parameters that the model has found during the training.\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(Unet_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_model = converter.convert()\n",
    "with open(\"quantized_model.tflite\", \"wb\") as f:\n",
    "  f.write(quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO]** Test the accuracy of the quantized model by writing your own \"evaluate\" function. Remember that TFLite interpreter can only process one sample at a time, not a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the interpreter\n",
    "interpreter = tf.lite.Interpreter('quantized_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def evaluate(interpreter, X_test, Y_test):\n",
    "  accuracies = []\n",
    "\n",
    "  for i, (input_data, true_class) in enumerate(zip(X_test, Y_test)):\n",
    "    input_data = input_data.astype(input_details[0]['dtype']) # read the image from the test dataset\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(input_data, axis=0)) # set the input tensor with the image and add a dimension for the batch\n",
    "\n",
    "    interpreter.invoke()  # run the inference on the image\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])  # get the output tensor of the model\n",
    "    predicted_class = np.squeeze(output_data) # remove the batch dimension\n",
    "    predicted_class = np.argmax(predicted_class, axis=2)  # get the class with the highest probability\n",
    "\n",
    "    true_class = np.squeeze(true_class) # remove the batch dimension  \n",
    "    accuracy = np.mean(predicted_class == true_class) # evaluate the accuracy of the model\n",
    "    accuracies.append(accuracy) # save the accuracy of the model\n",
    "\n",
    "    print(f\"Image {i+1} - Accuracy: {accuracy}\")  # print the accuracy of the model\n",
    "\n",
    "    plt.imshow(true_class, 'gray')  # show the image\n",
    "    plt.title('Ground trouth image')  \n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(predicted_class, 'gray') # show the predicted image\n",
    "    plt.title('Predicted image')\n",
    "    plt.show()\n",
    "  return np.mean(accuracies)\n",
    "# Call the evaluate function\n",
    "accuracy = evaluate(interpreter, X_test, Y_test)\n",
    "print(f\"Mean accuracy: {accuracy}\")\n",
    "\n",
    "original_predictions = Unet_model.predict(X_test)\n",
    "original_predictions = (original_predictions > 0.5).astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO]** Finetune the Keras model using quantization-aware training and measure the accuracy on the test set after actually quantizing it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best way to quantize the parameter is through QAT (Quantization Aware Training). This method consists in training the model to find the best parameters that can be quantized in int8.\n",
    "# So during the training the model will be aware that the parameters need to be quantized, so it will find the best values to be quantized.\n",
    "# A model quantized with QAT can perform similar to the original model, but with a lower memory occupation. Note that QAT model need an ad-hoc training and calibration.\n",
    "\n",
    "# cannot apply QAT to batch normalizer layers\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(Unet_model)\n",
    "quant_aware_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "quant_aware_model.fit(X_train, Y_train, epochs=50)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_aware_model = converter.convert()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMFmvMX5/hkWhRlEa6VXpi1",
   "collapsed_sections": [],
   "name": "lab5_solution.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
